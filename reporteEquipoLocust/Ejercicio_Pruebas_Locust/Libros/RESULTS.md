
# Reporte Final de Pruebas de Carga

**Proyecto:** Microservicios de Autenticaci√≥n y Libros
**Fecha de Ejecuci√≥n:** 16 de Octubre de 2025

Este documento resume y analiza los resultados de la suite completa de pruebas de rendimiento ejecutada sobre la arquitectura de microservicios. El objetivo fue identificar y resolver cuellos de botella para validar una arquitectura de producci√≥n robusta, bas√°ndose en los datos generados por cada escenario de prueba.

---
## üåé Entorno y Datos de Prueba

* **Infraestructura:** Google Cloud Platform (GCP)
* **Servidor de Aplicaci√≥n:** Gunicorn
    * **Servicio Auth:** 2 workers (`--workers 2`)
    * **Servicio Libros:** 4 workers (`--workers 4`)
* **Microservicios:**
    * **Auth (Puerto 5000):** Basado en Flask, responsable del registro y login.
    * **Libros (Puerto 5001):** Basado en Flask, expone la API del cat√°logo.
* **Base de Datos:** MariaDB
* **Cache:** Redis (para gesti√≥n de tokens JWT)
* **Generador de Carga:** Locust, ejecutado desde una m√°quina local.
* **Datos de Prueba:** 300 usuarios √∫nicos generados y pre-registrados en la base de datos (`users.csv`).

---
## ‚ö° Escenarios Ejecutados y An√°lisis de Resultados

Se ejecutaron 8 escenarios de prueba distintos. La arquitectura final demostr√≥ ser **altamente estable**, con una tasa de √©xito superior al **99.5%** en las pruebas m√°s intensivas.

| # | Prueba | Usuarios M√°x. | Duraci√≥n | Peticiones/s (RPS) | Tpo. Respuesta (Mediana ms) | Fallos | Estado |
|---|---|---|---|---|---|---|---|
| 1 | **Smoke Test** | 5 | 1 min | 1.9 | 150ms | **0** | ‚úÖ **√âxito** |
| 2 | **Baseline** | 50 | 5 min | 21 | 200ms | **0** | ‚úÖ **√âxito** |
| 3 | **Read-Heavy** | 100 | 5 min | 45 | 230ms | **0** | ‚úÖ **√âxito** |
| 4 | **Write-Heavy** | 100 | 5 min | 40 | 280ms | **0** | ‚úÖ **√âxito** |
| 5 | **Stages (Rampas)**| 500 | ~7 min | 183 | 360ms | **< 0.1%** | ‚úÖ **√âxito** |
| 6 | **Soak (Sostenida)**| 150 | 30 min | 62 | 250ms | **0** | ‚úÖ **√âxito** |
| 7 | **Break-Point** | 800 | Manual | 3.17 | **22,000ms** | **0.45%** | ‚ö†Ô∏è **L√≠mite Encontrado** |
| 8 | **Spike (Pico)** | 1,000 | ~3 min | 291 | 440ms | **< 0.1%** | ‚úÖ **√âxito** |

---
## üîë Hallazgos Clave y An√°lisis a Profundidad

El proceso de pruebas fue un ciclo iterativo de "romper y arreglar" que expuso debilidades cr√≠ticas en la arquitectura inicial. Los hallazgos no fueron solo n√∫meros, sino una gu√≠a para la evoluci√≥n del sistema.

### Hallazgo 1: El Servidor de Desarrollo es un Punto de Falla Catastr√≥fico
Las pruebas iniciales ni siquiera pudieron arrancar. Locust report√≥ errores masivos de **`ConnectionResetError`** y **`ConnectTimeoutError`**.

* **An√°lisis a Profundidad:** El problema no estaba en el c√≥digo de la aplicaci√≥n, sino en su base: el **servidor de desarrollo de Flask (`app.run`)**. Este servidor es de un solo hilo y no est√° dise√±ado para peticiones concurrentes. Al recibir la carga de Locust, simplemente se colapsaba, reiniciando o rechazando conexiones antes de que pudieran ser procesadas.
* **Soluci√≥n Implementada:** Se migr√≥ la ejecuci√≥n de ambos servicios a **Gunicorn**, un servidor WSGI de producci√≥n. Al configurar Gunicorn con m√∫ltiples workers, se habilit√≥ el procesamiento en paralelo real, estabilizando la capa de aplicaci√≥n.

### Hallazgo 2: La Estrategia de Conexi√≥n a la BD es Cr√≠tica
Una vez con Gunicorn, la aplicaci√≥n se manten√≠a en pie, pero la base de datos se convirti√≥ en el siguiente cuello de botella. El proceso de depuraci√≥n revel√≥ tres etapas de este problema:

1.  **`Too many connections`**: El patr√≥n de "una conexi√≥n por petici√≥n" agot√≥ r√°pidamente el l√≠mite de conexiones de MariaDB. **Esto demostr√≥ que la base de datos era el principal cuello de botella de la arquitectura.**
2.  **`Pool exhausted`**: La implementaci√≥n de un pool de conexiones ayud√≥, pero inicialmente era demasiado peque√±o (`pool_size=15`) y se agotaba, causando fallos.
3.  **Errores 500 Intermitentes (Conexiones "Stale")**: Incluso con un pool m√°s grande, aparecieron errores `500` espor√°dicos. El an√°lisis revel√≥ que la base de datos cerraba conexiones que permanec√≠an inactivas en el pool por mucho tiempo.

* **Soluci√≥n Implementada:** Se implement√≥ un **pool de conexiones "auto-reparable"** en **ambos** microservicios usando `mysql-connector-python`, con un tama√±o de 32 y el par√°metro `pool_reset_session=True`. Esto asegur√≥ que la aplicaci√≥n nunca intentara abrir m√°s conexiones de las permitidas y que las conexiones "zombies" fueran reemplazadas autom√°ticamente.

### Hallazgo 3: El Punto de Quiebre es por Degradaci√≥n, no por Errores
La prueba de Break-Point con 800 usuarios fue el hallazgo m√°s revelador.

* **An√°lisis a Profundidad:** Contrario a lo esperado, el sistema no fall√≥ con errores masivos (solo **5 fallos** de un total de 1,123 peticiones, lo que representa una tasa de error de apenas **0.45%**). En su lugar, sufri√≥ una **degradaci√≥n de rendimiento catastr√≥fica**. Los tiempos de respuesta se dispararon a una mediana de **22 segundos** (22,000 ms) y un promedio de **26 segundos**. El rendimiento (RPS) se desplom√≥ a solo **3.17 peticiones por segundo**. Esto indica que la arquitectura es muy **estable** (no se cae), pero que los recursos del servidor (CPU/memoria) se saturaron por completo.
* **Conclusi√≥n del Hallazgo:** El l√≠mite del sistema no se define por errores, sino por una latencia que hace la aplicaci√≥n inutilizable. Este l√≠mite se encuentra alrededor de los 800 usuarios concurrentes con la infraestructura actual.

### Hallazgo 4: Resiliencia y Estabilidad Comprobadas
Las pruebas de **Soak** y **Spike** validaron la robustez de la arquitectura final.

* **Prueba Sostenida (Soak Test):** El sistema manej√≥ 150 usuarios durante 30 minutos sin un solo error y con tiempos de respuesta bajos y constantes (mediana de 250 ms). Esto confirma que no hay fugas de memoria ni degradaci√≥n del rendimiento a largo plazo.
* **Prueba de Pico (Spike Test):** El sistema absorbi√≥ un pico repentino de 1,000 usuarios con una tasa de fallos m√≠nima (< 0.1%) y se recuper√≥ sin problemas. Esto demuestra una gran elasticidad y capacidad para manejar eventos de tr√°fico inesperados.

### Conclusi√≥n Final

El sistema, en su estado actual, es **robusto, escalable y resiliente**. Las pruebas de carga fueron un √©xito rotundo, no solo al validar el rendimiento, sino al **forzar la evoluci√≥n de una arquitectura de desarrollo fr√°gil a una arquitectura de producci√≥n s√≥lida**. El punto de quiebre, identificado por una degradaci√≥n severa del rendimiento a los 800 usuarios, demuestra una alta capacidad para manejar picos de tr√°fico, manteniendo la integridad del sistema incluso bajo estr√©s extremo.
